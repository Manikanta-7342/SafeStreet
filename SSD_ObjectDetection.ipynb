{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49d9057a-9209-4d76-bde2-a906391b9d0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-18 07:30:45.941951: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-18 07:30:46.072496: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /glob/development-tools/versions/oneapi/2023.0.1/oneapi/vpl/2023.0.0/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/tbb/2021.8.0/env/../lib/intel64/gcc4.8:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/rkcommon/1.10.0/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/ospray_studio/0.11.1/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/ospray/2.10.0/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/openvkl/1.3.1/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/oidn/1.4.3/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/mpi/2021.8.0//libfabric/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/mpi/2021.8.0//lib/release:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/mpi/2021.8.0//lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/mkl/2023.0.0/lib/intel64:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/itac/2021.8.0/slib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/ispc/1.18.1/lib/lib64:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/ipp/2021.7.0/lib/intel64:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/ippcp/2021.6.3/lib/intel64:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/ipp/2021.7.0/lib/intel64:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/embree/3.13.5/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/dnnl/2023.0.0/cpu_dpcpp_gpu_dpcpp/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/debugger/2023.0.0/gdb/intel64/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/debugger/2023.0.0/libipt/intel64/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/debugger/2023.0.0/dep/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/dal/2023.0.0/lib/intel64:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/compiler/2023.0.0/linux/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/compiler/2023.0.0/linux/lib/x64:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/compiler/2023.0.0/linux/lib/oclfpga/host/linux64/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/compiler/2023.0.0/linux/compiler/lib/intel64_lin:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/ccl/2021.8.0/lib/cpu_gpu_dpcpp\n",
      "2023-03-18 07:30:46.072537: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-03-18 07:30:49.016293: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /glob/development-tools/versions/oneapi/2023.0.1/oneapi/vpl/2023.0.0/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/tbb/2021.8.0/env/../lib/intel64/gcc4.8:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/rkcommon/1.10.0/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/ospray_studio/0.11.1/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/ospray/2.10.0/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/openvkl/1.3.1/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/oidn/1.4.3/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/mpi/2021.8.0//libfabric/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/mpi/2021.8.0//lib/release:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/mpi/2021.8.0//lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/mkl/2023.0.0/lib/intel64:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/itac/2021.8.0/slib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/ispc/1.18.1/lib/lib64:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/ipp/2021.7.0/lib/intel64:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/ippcp/2021.6.3/lib/intel64:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/ipp/2021.7.0/lib/intel64:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/embree/3.13.5/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/dnnl/2023.0.0/cpu_dpcpp_gpu_dpcpp/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/debugger/2023.0.0/gdb/intel64/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/debugger/2023.0.0/libipt/intel64/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/debugger/2023.0.0/dep/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/dal/2023.0.0/lib/intel64:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/compiler/2023.0.0/linux/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/compiler/2023.0.0/linux/lib/x64:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/compiler/2023.0.0/linux/lib/oclfpga/host/linux64/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/compiler/2023.0.0/linux/compiler/lib/intel64_lin:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/ccl/2021.8.0/lib/cpu_gpu_dpcpp\n",
      "2023-03-18 07:30:49.016668: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /glob/development-tools/versions/oneapi/2023.0.1/oneapi/vpl/2023.0.0/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/tbb/2021.8.0/env/../lib/intel64/gcc4.8:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/rkcommon/1.10.0/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/ospray_studio/0.11.1/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/ospray/2.10.0/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/openvkl/1.3.1/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/oidn/1.4.3/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/mpi/2021.8.0//libfabric/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/mpi/2021.8.0//lib/release:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/mpi/2021.8.0//lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/mkl/2023.0.0/lib/intel64:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/itac/2021.8.0/slib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/ispc/1.18.1/lib/lib64:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/ipp/2021.7.0/lib/intel64:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/ippcp/2021.6.3/lib/intel64:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/ipp/2021.7.0/lib/intel64:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/embree/3.13.5/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/dnnl/2023.0.0/cpu_dpcpp_gpu_dpcpp/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/debugger/2023.0.0/gdb/intel64/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/debugger/2023.0.0/libipt/intel64/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/debugger/2023.0.0/dep/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/dal/2023.0.0/lib/intel64:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/compiler/2023.0.0/linux/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/compiler/2023.0.0/linux/lib/x64:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/compiler/2023.0.0/linux/lib/oclfpga/host/linux64/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/compiler/2023.0.0/linux/compiler/lib/intel64_lin:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/ccl/2021.8.0/lib/cpu_gpu_dpcpp\n",
      "2023-03-18 07:30:49.016688: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99f7bc6a-c618-477b-ba44-c14e134a3e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "imsize = (512, 512)\n",
    "pb_dir = './ssd_inception_v2_coco_2017_11_17/frozen_inference_graph.pb'\n",
    "im_output = './Test/images/'\n",
    "num_pred = 30\n",
    "density = {'car': 2, 'bus': 4, 'truck': 4, 'person': 0.5, 'bicycle': 0.5, 'motorcycle': 1}\n",
    "batch_size = 1\n",
    "frames_to_skip = 5\n",
    "frame_w = frame_h = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd5739c7-2e72-48e9-8757-bf719b80aebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_boxes(image_fed, bbox, classes):\n",
    "\n",
    "\tfor i in range(best_boxes_roi.shape[0]):\n",
    "\t\tim = np.reshape(image_fed[i], (frame_w, frame_h, 3))\n",
    "\n",
    "\t\tfor j in range(num_pred):\n",
    "\t\t\tif best_boxes_scores[i][j] > 0.15:\n",
    "\t\t\t\tx = int(best_boxes_roi[i][j][1])\n",
    "\t\t\t\ty = int(best_boxes_roi[i][j][0])\n",
    "\t\t\t\tx_max = int(best_boxes_roi[i][j][3])\n",
    "\t\t\t\ty_max = int(best_boxes_roi[i][j][2])\n",
    "\n",
    "\t\t\t\tcv2.rectangle(im, (x,y), (x_max,y_max), (0,255,0), 2)\n",
    "\t\t\t\tfont = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\t\t\t\tcv2.putText(im, labels[int(classes[i][j])], (x,y), font, 1e-3*frame_h, (255,0,0), 2)\n",
    "\t\t\t\t#cv2.imshow('Output',im)\n",
    "\t\tif i == 0:\n",
    "\t\t\tcv2.imwrite(im_output+'east_bbox.png', im)\n",
    "\t\tif i == 1:\n",
    "\t\t\tcv2.imwrite(im_output+'west_bbox.png', im)\n",
    "\t\tif i == 2:\n",
    "\t\t\tcv2.imwrite(im_output+'north_bbox.png', im)\n",
    "\t\tif i == 3:\n",
    "\t\t\tcv2.imwrite(im_output+'south_bbox.png', im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e27a9ab4-ff01-4eac-81e5-24473f6975f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-18 07:48:47.222783: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/u184510/.local/lib/python3.9/site-packages/cv2/../../lib64:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/vpl/2023.0.0/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/tbb/2021.8.0/env/../lib/intel64/gcc4.8:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/rkcommon/1.10.0/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/ospray_studio/0.11.1/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/ospray/2.10.0/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/openvkl/1.3.1/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/oidn/1.4.3/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/mpi/2021.8.0//libfabric/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/mpi/2021.8.0//lib/release:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/mpi/2021.8.0//lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/mkl/2023.0.0/lib/intel64:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/itac/2021.8.0/slib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/ispc/1.18.1/lib/lib64:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/ipp/2021.7.0/lib/intel64:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/ippcp/2021.6.3/lib/intel64:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/ipp/2021.7.0/lib/intel64:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/embree/3.13.5/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/dnnl/2023.0.0/cpu_dpcpp_gpu_dpcpp/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/debugger/2023.0.0/gdb/intel64/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/debugger/2023.0.0/libipt/intel64/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/debugger/2023.0.0/dep/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/dal/2023.0.0/lib/intel64:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/compiler/2023.0.0/linux/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/compiler/2023.0.0/linux/lib/x64:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/compiler/2023.0.0/linux/lib/oclfpga/host/linux64/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/compiler/2023.0.0/linux/compiler/lib/intel64_lin:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/ccl/2021.8.0/lib/cpu_gpu_dpcpp\n",
      "2023-03-18 07:48:47.222859: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-03-18 07:48:47.222901: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (s001-n025): /proc/driver/nvidia/version does not exist\n",
      "2023-03-18 07:48:47.232569: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "#loading the prtrained model\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "\twith tf.io.gfile.GFile(pb_dir, 'rb') as file:\n",
    "\t\tgraph_def = tf.compat.v1.GraphDef()\n",
    "\t\tgraph_def.ParseFromString(file.read())\n",
    "\t\ttf.import_graph_def(graph_def, name='')\n",
    "\n",
    "\t\timg = graph.get_tensor_by_name('image_tensor:0')\n",
    "\t\tdetection_boxes = graph.get_tensor_by_name('detection_boxes:0')\n",
    "\t\tdetection_scores = graph.get_tensor_by_name('detection_scores:0')\n",
    "\t\tnum_detections = graph.get_tensor_by_name('num_detections:0')\n",
    "\t\tdetection_classes = graph.get_tensor_by_name('detection_classes:0')\n",
    "\t\tsess = tf.compat.v1.Session(graph=graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba88409b-6da9-4840-ad96-b9707b26cfac",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "with open('Test/labels.txt', 'r') as file:\n",
    "\tfor line in file.read().splitlines():\n",
    "\t\ta = line.split()#.readline()\n",
    "\t\ta = a[-1]\n",
    "\t\t#label = label.replace('\\n', '')\n",
    "\t\ta = str(a)\n",
    "\t\tlabels.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "862b8e1d-735a-4449-91a1-026280a9a4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "vid_inp_east = './Test/videos/7.0.1080.mp4'\n",
    "vid_inp_west = './Test/videos/6.0.720.mp4'\n",
    "vid_inp_north = './Test/videos/3.2.1080.mp4'\n",
    "vid_inp_south = './Test/videos/2.0.480.mp4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3a1d8855-e5f7-46de-8a0e-cc145806f6c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[mov,mp4,m4a,3gp,3g2,mj2 @ 0x55e4edee6f40] moov atom not found\n"
     ]
    }
   ],
   "source": [
    "video_reader_east = cv2.VideoCapture(vid_inp_east)\n",
    "video_reader_west = cv2.VideoCapture(vid_inp_west)\n",
    "video_reader_north = cv2.VideoCapture(vid_inp_north)\n",
    "video_reader_south = cv2.VideoCapture(vid_inp_south)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d2948f69-621d-4fb3-84d9-8abe11e73ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "li_1=[]\n",
    "li_2=[]\n",
    "li_3=[]\n",
    "li_4=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bc194670-a472-479c-a3a4-79ac62c9d32e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video_Ended\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "\twhile True:\n",
    "\t\tdensity_score = [0, 0, 0, 0]\n",
    "\t\timage_bat = []\n",
    "\n",
    "\t\tfor j in range(batch_size):\n",
    "\t\t\tret, image = video_reader_east.read()\n",
    "\t\t\timage = cv2.resize(image, imsize)\n",
    "\t\t\timage_bat.append(image)\n",
    "\t\t\tcv2.imwrite(im_output + 'east.png', image)\n",
    "\n",
    "\t\t\tret, image = video_reader_west.read()\n",
    "\t\t\timage = cv2.resize(image, imsize)\n",
    "\t\t\timage_bat.append(image)\n",
    "\t\t\tcv2.imwrite(im_output + 'west.png', image)\n",
    "\n",
    "\t\t\tret, image = video_reader_north.read()\n",
    "\t\t\timage = cv2.resize(image, imsize)\n",
    "\t\t\timage_bat.append(image)\n",
    "\t\t\tcv2.imwrite(im_output + 'north.png', image)\n",
    "\n",
    "\t\t\tret, image = video_reader_south.read()\n",
    "\t\t\timage = cv2.resize(image, imsize)\n",
    "\t\t\timage_bat.append(image)\n",
    "\t\t\tcv2.imwrite(im_output + 'south.png', image)\n",
    "\n",
    "\t\tfor k in range(frames_to_skip):\n",
    "\t\t\tvideo_reader_east.grab()\n",
    "\t\t\tvideo_reader_west.grab()\n",
    "\t\t\tvideo_reader_north.grab()\n",
    "\t\tfor _ in range(2):\n",
    "\t\t\tvideo_reader_south.grab()\n",
    "\n",
    "\t\timage_batch = np.asarray(image_bat)\n",
    "\t\tfeed_dict = {img: image_batch}\n",
    "\t\t# print('Images read\\nEvaluating....')\n",
    "\t\ttick = time.time()\n",
    "\t\ty_p_boxes, y_p_scores, y_p_num_detections, y_p_classes = sess.run([detection_boxes,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t   detection_scores,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t   num_detections,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t   detection_classes], feed_dict=feed_dict)\n",
    "\t\tprint('\\n\\n', 'Time taken: ', time.time() - tick)\n",
    "\n",
    "\t\tbest_boxes_roi = []\n",
    "\t\tbest_boxes_scores = []\n",
    "\t\tbest_boxes_classes = []\n",
    "\t\tfor i in range(y_p_boxes.shape[0]):\n",
    "\t\t\ttemp = y_p_boxes[i, :num_pred] * frame_h\n",
    "\t\t\tbest_boxes_roi.append(temp)\n",
    "\t\t\tbest_boxes_scores.append(y_p_scores[i, :num_pred])\n",
    "\t\t\tbest_boxes_classes.append(y_p_classes[i, :num_pred])\n",
    "\t\tbest_boxes_roi = np.asarray(best_boxes_roi)\n",
    "\t\tbest_boxes_scores = np.asarray(best_boxes_scores)\n",
    "\t\tbest_boxes_classes = np.asarray(best_boxes_classes)\n",
    "\n",
    "\t\tdraw_boxes(image_batch, best_boxes_roi, best_boxes_classes)\n",
    "\n",
    "\t\tfor i in range(4):\n",
    "\t\t\tfor j in range(num_pred):\n",
    "\t\t\t\tif (best_boxes_scores[i][j] > 0.15) and (labels[int(best_boxes_classes[i][j])] in density.keys()):\n",
    "\t\t\t\t\tdensity_score[i] += density[labels[int(best_boxes_classes[i][j])]]\n",
    "\n",
    "\t\teast = density_score[0]\n",
    "\t\twest = density_score[1]\n",
    "\t\tnorth = density_score[2]\n",
    "\t\tsouth = density_score[3]\n",
    "\n",
    "\t\tdensity_score[0] = east\n",
    "\t\tdensity_score[1] = south\n",
    "\t\tdensity_score[2] = west\n",
    "\t\tdensity_score[3] = north\n",
    "\n",
    "\t\tli_1.append(east)\n",
    "\t\tli_2.append(south)\n",
    "\t\tli_3.append(west)\n",
    "\t\tli_4.append(north)\n",
    "\t\twith open('./Resources/text_files/val.txt', 'w') as file:\n",
    "\t\t\tfile.write(str(density_score))\n",
    "\n",
    "\t\tprint(\"Density_Score\", \"-------------------------\", density_score)\n",
    "except:\n",
    "\tprint(\"Video_Ended\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9535b5d2-a863-44a2-bb13-2f122cf109e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_reader_east.release()\n",
    "video_reader_west.release()\n",
    "video_reader_north.release()\n",
    "video_reader_south.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (IntelÂ® oneAPI 2023.0)",
   "language": "python",
   "name": "c009-intel_distribution_of_python_3_oneapi-beta05-python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
