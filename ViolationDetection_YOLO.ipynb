{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7da7b3d-1ef5-44e6-9d66-da16a45ed209",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-18 07:26:12.246863: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-18 07:26:16.865784: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /glob/development-tools/versions/oneapi/2023.0.1/oneapi/vpl/2023.0.0/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/tbb/2021.8.0/env/../lib/intel64/gcc4.8:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/rkcommon/1.10.0/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/ospray_studio/0.11.1/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/ospray/2.10.0/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/openvkl/1.3.1/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/oidn/1.4.3/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/mpi/2021.8.0//libfabric/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/mpi/2021.8.0//lib/release:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/mpi/2021.8.0//lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/mkl/2023.0.0/lib/intel64:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/itac/2021.8.0/slib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/ispc/1.18.1/lib/lib64:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/ipp/2021.7.0/lib/intel64:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/ippcp/2021.6.3/lib/intel64:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/ipp/2021.7.0/lib/intel64:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/embree/3.13.5/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/dnnl/2023.0.0/cpu_dpcpp_gpu_dpcpp/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/debugger/2023.0.0/gdb/intel64/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/debugger/2023.0.0/libipt/intel64/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/debugger/2023.0.0/dep/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/dal/2023.0.0/lib/intel64:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/compiler/2023.0.0/linux/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/compiler/2023.0.0/linux/lib/x64:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/compiler/2023.0.0/linux/lib/oclfpga/host/linux64/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/compiler/2023.0.0/linux/compiler/lib/intel64_lin:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/ccl/2021.8.0/lib/cpu_gpu_dpcpp\n",
      "2023-03-18 07:26:16.865827: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-03-18 07:26:32.135324: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /glob/development-tools/versions/oneapi/2023.0.1/oneapi/vpl/2023.0.0/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/tbb/2021.8.0/env/../lib/intel64/gcc4.8:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/rkcommon/1.10.0/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/ospray_studio/0.11.1/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/ospray/2.10.0/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/openvkl/1.3.1/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/oidn/1.4.3/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/mpi/2021.8.0//libfabric/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/mpi/2021.8.0//lib/release:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/mpi/2021.8.0//lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/mkl/2023.0.0/lib/intel64:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/itac/2021.8.0/slib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/ispc/1.18.1/lib/lib64:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/ipp/2021.7.0/lib/intel64:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/ippcp/2021.6.3/lib/intel64:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/ipp/2021.7.0/lib/intel64:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/embree/3.13.5/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/dnnl/2023.0.0/cpu_dpcpp_gpu_dpcpp/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/debugger/2023.0.0/gdb/intel64/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/debugger/2023.0.0/libipt/intel64/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/debugger/2023.0.0/dep/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/dal/2023.0.0/lib/intel64:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/compiler/2023.0.0/linux/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/compiler/2023.0.0/linux/lib/x64:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/compiler/2023.0.0/linux/lib/oclfpga/host/linux64/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/compiler/2023.0.0/linux/compiler/lib/intel64_lin:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/ccl/2021.8.0/lib/cpu_gpu_dpcpp\n",
      "2023-03-18 07:26:32.140716: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /glob/development-tools/versions/oneapi/2023.0.1/oneapi/vpl/2023.0.0/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/tbb/2021.8.0/env/../lib/intel64/gcc4.8:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/rkcommon/1.10.0/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/ospray_studio/0.11.1/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/ospray/2.10.0/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/openvkl/1.3.1/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/oidn/1.4.3/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/mpi/2021.8.0//libfabric/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/mpi/2021.8.0//lib/release:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/mpi/2021.8.0//lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/mkl/2023.0.0/lib/intel64:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/itac/2021.8.0/slib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/ispc/1.18.1/lib/lib64:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/ipp/2021.7.0/lib/intel64:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/ippcp/2021.6.3/lib/intel64:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/ipp/2021.7.0/lib/intel64:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/embree/3.13.5/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/dnnl/2023.0.0/cpu_dpcpp_gpu_dpcpp/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/debugger/2023.0.0/gdb/intel64/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/debugger/2023.0.0/libipt/intel64/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/debugger/2023.0.0/dep/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/dal/2023.0.0/lib/intel64:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/compiler/2023.0.0/linux/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/compiler/2023.0.0/linux/lib/x64:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/compiler/2023.0.0/linux/lib/oclfpga/host/linux64/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/compiler/2023.0.0/linux/compiler/lib/intel64_lin:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/ccl/2021.8.0/lib/cpu_gpu_dpcpp\n",
      "2023-03-18 07:26:32.140752: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.layers import Conv2D, Input, BatchNormalization, LeakyReLU, ZeroPadding2D, UpSampling2D\n",
    "from keras.layers import add, concatenate\n",
    "from keras.models import Model\n",
    "import struct\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88933c1f-1282-4176-9eb1-52d90ad8d56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightReader:\n",
    "    def __init__(self, weight_file):\n",
    "        with open(weight_file, 'rb') as w_f:\n",
    "            major, = struct.unpack('i', w_f.read(4))\n",
    "            minor, = struct.unpack('i', w_f.read(4))\n",
    "            revision, = struct.unpack('i', w_f.read(4))\n",
    "\n",
    "            if (major * 10 + minor) >= 2 and major < 1000 and minor < 1000:\n",
    "                w_f.read(8)\n",
    "            else:\n",
    "                w_f.read(4)\n",
    "\n",
    "            transpose = (major > 1000) or (minor > 1000)\n",
    "\n",
    "            binary = w_f.read()\n",
    "\n",
    "        self.offset = 0\n",
    "        self.all_weights = np.frombuffer(binary, dtype='float32')\n",
    "\n",
    "    def read_bytes(self, size):\n",
    "        self.offset = self.offset + size\n",
    "        return self.all_weights[self.offset - size:self.offset]\n",
    "\n",
    "    def load_weights(self, model):\n",
    "        for i in range(106):\n",
    "            try:\n",
    "                conv_layer = model.get_layer('conv_' + str(i))\n",
    "                print(\"loading weights of convolution #\" + str(i))\n",
    "\n",
    "                if i not in [81, 93, 105]:\n",
    "                    norm_layer = model.get_layer('bnorm_' + str(i))\n",
    "\n",
    "                    size = np.prod(norm_layer.get_weights()[0].shape)\n",
    "\n",
    "                    beta = self.read_bytes(size)  # bias\n",
    "                    gamma = self.read_bytes(size)  # scale\n",
    "                    mean = self.read_bytes(size)  # mean\n",
    "                    var = self.read_bytes(size)  # variance\n",
    "\n",
    "                    weights = norm_layer.set_weights([gamma, beta, mean, var])\n",
    "\n",
    "                if len(conv_layer.get_weights()) > 1:\n",
    "                    bias = self.read_bytes(np.prod(conv_layer.get_weights()[1].shape))\n",
    "                    kernel = self.read_bytes(np.prod(conv_layer.get_weights()[0].shape))\n",
    "\n",
    "                    kernel = kernel.reshape(list(reversed(conv_layer.get_weights()[0].shape)))\n",
    "                    kernel = kernel.transpose([2, 3, 1, 0])\n",
    "                    conv_layer.set_weights([kernel, bias])\n",
    "                else:\n",
    "                    kernel = self.read_bytes(np.prod(conv_layer.get_weights()[0].shape))\n",
    "                    kernel = kernel.reshape(list(reversed(conv_layer.get_weights()[0].shape)))\n",
    "                    kernel = kernel.transpose([2, 3, 1, 0])\n",
    "                    conv_layer.set_weights([kernel])\n",
    "            except ValueError:\n",
    "                print(\"no convolution #\" + str(i))\n",
    "\n",
    "    def reset(self):\n",
    "        self.offset = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3a60654-0703-438b-a734-ad91ba77e0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BoundBox:\n",
    "    def __init__(self, xmin, ymin, xmax, ymax, objness=None, classes=None):\n",
    "        self.xmin = xmin\n",
    "        self.ymin = ymin\n",
    "        self.xmax = xmax\n",
    "        self.ymax = ymax\n",
    "\n",
    "        self.objness = objness\n",
    "        self.classes = classes\n",
    "\n",
    "        self.label = -1\n",
    "        self.score = -1\n",
    "\n",
    "    def get_label(self):\n",
    "        if self.label == -1:\n",
    "            self.label = np.argmax(self.classes)\n",
    "\n",
    "        return self.label\n",
    "\n",
    "    def get_score(self):\n",
    "        if self.score == -1:\n",
    "            self.score = self.classes[self.get_label()]\n",
    "\n",
    "        return self.score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7376a9a2-ec75-42e4-92ca-aed9f1fa76cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _conv_block(inp, convs, skip=True):\n",
    "    x = inp\n",
    "    count = 0\n",
    "\n",
    "    for conv in convs:\n",
    "        if count == (len(convs) - 2) and skip:\n",
    "            skip_connection = x\n",
    "        count += 1\n",
    "\n",
    "        if conv['stride'] > 1: x = ZeroPadding2D(((1, 0), (1, 0)))(x)  # peculiar padding as darknet prefer left and top\n",
    "        x = Conv2D(conv['filter'],\n",
    "                   conv['kernel'],\n",
    "                   strides=conv['stride'],\n",
    "                   padding='valid' if conv['stride'] > 1 else 'same',  # peculiar padding as darknet prefer left and top\n",
    "                   name='conv_' + str(conv['layer_idx']),\n",
    "                   use_bias=False if conv['bnorm'] else True)(x)\n",
    "        if conv['bnorm']: x = BatchNormalization(epsilon=0.001, name='bnorm_' + str(conv['layer_idx']))(x)\n",
    "        if conv['leaky']: x = LeakyReLU(alpha=0.1, name='leaky_' + str(conv['layer_idx']))(x)\n",
    "\n",
    "    return add([skip_connection, x]) if skip else x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86bdcd93-34b4-4f0f-90e6-1b15ed301d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _interval_overlap(interval_a, interval_b):\n",
    "    x1, x2 = interval_a\n",
    "    x3, x4 = interval_b\n",
    "\n",
    "    if x3 < x1:\n",
    "        if x4 < x1:\n",
    "            return 0\n",
    "        else:\n",
    "            return min(x2, x4) - x1\n",
    "    else:\n",
    "        if x2 < x3:\n",
    "            return 0\n",
    "        else:\n",
    "            return min(x2, x4) - x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13584802-f0bb-46e7-b7d1-1c4f0aee03ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _sigmoid(x):\n",
    "    return 1. / (1. + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b65b85d6-a42e-4401-8246-439df05645a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bbox_iou(box1, box2):\n",
    "    intersect_w = _interval_overlap([box1.xmin, box1.xmax], [box2.xmin, box2.xmax])\n",
    "    intersect_h = _interval_overlap([box1.ymin, box1.ymax], [box2.ymin, box2.ymax])\n",
    "\n",
    "    intersect = intersect_w * intersect_h\n",
    "\n",
    "    w1, h1 = box1.xmax - box1.xmin, box1.ymax - box1.ymin\n",
    "    w2, h2 = box2.xmax - box2.xmin, box2.ymax - box2.ymin\n",
    "\n",
    "    union = w1 * h1 + w2 * h2 - intersect\n",
    "\n",
    "    return float(intersect) / union\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9a87e31-edfe-4534-8ba2-06af1b035253",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_yolov3_model():\n",
    "    input_image = Input(shape=(None, None, 3))\n",
    "\n",
    "    # Layer  0 => 4\n",
    "    x = _conv_block(input_image,\n",
    "                    [{'filter': 32, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 0},\n",
    "                     {'filter': 64, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 1},\n",
    "                     {'filter': 32, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 2},\n",
    "                     {'filter': 64, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 3}])\n",
    "\n",
    "    # Layer  5 => 8\n",
    "    x = _conv_block(x, [{'filter': 128, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 5},\n",
    "                        {'filter': 64, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 6},\n",
    "                        {'filter': 128, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 7}])\n",
    "\n",
    "    # Layer  9 => 11\n",
    "    x = _conv_block(x, [{'filter': 64, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 9},\n",
    "                        {'filter': 128, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 10}])\n",
    "\n",
    "    # Layer 12 => 15\n",
    "    x = _conv_block(x, [{'filter': 256, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 12},\n",
    "                        {'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 13},\n",
    "                        {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 14}])\n",
    "\n",
    "    # Layer 16 => 36\n",
    "    for i in range(7):\n",
    "        x = _conv_block(x, [\n",
    "            {'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 16 + i * 3},\n",
    "            {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 17 + i * 3}])\n",
    "\n",
    "    skip_36 = x\n",
    "\n",
    "    # Layer 37 => 40\n",
    "    x = _conv_block(x, [{'filter': 512, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 37},\n",
    "                        {'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 38},\n",
    "                        {'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 39}])\n",
    "\n",
    "    # Layer 41 => 61\n",
    "    for i in range(7):\n",
    "        x = _conv_block(x, [\n",
    "            {'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 41 + i * 3},\n",
    "            {'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 42 + i * 3}])\n",
    "\n",
    "    skip_61 = x\n",
    "\n",
    "    # Layer 62 => 65\n",
    "    x = _conv_block(x, [{'filter': 1024, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 62},\n",
    "                        {'filter': 512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 63},\n",
    "                        {'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 64}])\n",
    "\n",
    "    # Layer 66 => 74\n",
    "    for i in range(3):\n",
    "        x = _conv_block(x, [\n",
    "            {'filter': 512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 66 + i * 3},\n",
    "            {'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 67 + i * 3}])\n",
    "\n",
    "    # Layer 75 => 79\n",
    "    x = _conv_block(x, [{'filter': 512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 75},\n",
    "                        {'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 76},\n",
    "                        {'filter': 512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 77},\n",
    "                        {'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 78},\n",
    "                        {'filter': 512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 79}],\n",
    "                    skip=False)\n",
    "\n",
    "    # Layer 80 => 82\n",
    "    yolo_82 = _conv_block(x, [{'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 80},\n",
    "                              {'filter': 255, 'kernel': 1, 'stride': 1, 'bnorm': False, 'leaky': False,\n",
    "                               'layer_idx': 81}], skip=False)\n",
    "\n",
    "    # Layer 83 => 86\n",
    "    x = _conv_block(x, [{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 84}],\n",
    "                    skip=False)\n",
    "    x = UpSampling2D(2)(x)\n",
    "    x = concatenate([x, skip_61])\n",
    "\n",
    "    # Layer 87 => 91\n",
    "    x = _conv_block(x, [{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 87},\n",
    "                        {'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 88},\n",
    "                        {'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 89},\n",
    "                        {'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 90},\n",
    "                        {'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 91}],\n",
    "                    skip=False)\n",
    "\n",
    "    # Layer 92 => 94\n",
    "    yolo_94 = _conv_block(x, [{'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 92},\n",
    "                              {'filter': 255, 'kernel': 1, 'stride': 1, 'bnorm': False, 'leaky': False,\n",
    "                               'layer_idx': 93}], skip=False)\n",
    "\n",
    "    # Layer 95 => 98\n",
    "    x = _conv_block(x, [{'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 96}],\n",
    "                    skip=False)\n",
    "    x = UpSampling2D(2)(x)\n",
    "    x = concatenate([x, skip_36])\n",
    "\n",
    "    # Layer 99 => 106\n",
    "    yolo_106 = _conv_block(x, [{'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 99},\n",
    "                               {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True,\n",
    "                                'layer_idx': 100},\n",
    "                               {'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True,\n",
    "                                'layer_idx': 101},\n",
    "                               {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True,\n",
    "                                'layer_idx': 102},\n",
    "                               {'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True,\n",
    "                                'layer_idx': 103},\n",
    "                               {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True,\n",
    "                                'layer_idx': 104},\n",
    "                               {'filter': 255, 'kernel': 1, 'stride': 1, 'bnorm': False, 'leaky': False,\n",
    "                                'layer_idx': 105}], skip=False)\n",
    "\n",
    "    model = Model(input_image, [yolo_82, yolo_94, yolo_106])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "206c1110-b4d4-4577-944c-f4614cd1ce6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_input(image, net_h, net_w):\n",
    "    new_h, new_w, _ = image.shape\n",
    "\n",
    "    # determine the new size of the image\n",
    "    if (float(net_w) / new_w) < (float(net_h) / new_h):\n",
    "        new_h = (new_h * net_w) / new_w\n",
    "        new_w = net_w\n",
    "    else:\n",
    "        new_w = (new_w * net_h) / new_h\n",
    "        new_h = net_h\n",
    "\n",
    "    # resize the image to the new size\n",
    "    resized = cv2.resize(image[:, :, ::-1] / 255., (int(new_w), int(new_h)))\n",
    "\n",
    "    # embed the image into the standard letter box\n",
    "    new_image = np.ones((net_h, net_w, 3)) * 0.5\n",
    "    new_image[int((net_h - new_h) // 2):int((net_h + new_h) // 2), int((net_w - new_w) // 2):int((net_w + new_w) // 2),\n",
    "    :] = resized\n",
    "    new_image = np.expand_dims(new_image, 0)\n",
    "\n",
    "    return new_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "80ff3c39-ae16-4086-b222-60e3d4979dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_netout(netout, anchors, obj_thresh, nms_thresh, net_h, net_w):\n",
    "    grid_h, grid_w = netout.shape[:2]\n",
    "    nb_box = 3\n",
    "    netout = netout.reshape((grid_h, grid_w, nb_box, -1))\n",
    "    nb_class = netout.shape[-1] - 5\n",
    "\n",
    "    boxes = []\n",
    "\n",
    "    netout[..., :2] = _sigmoid(netout[..., :2])\n",
    "    netout[..., 4:] = _sigmoid(netout[..., 4:])\n",
    "    netout[..., 5:] = netout[..., 4][..., np.newaxis] * netout[..., 5:]\n",
    "    netout[..., 5:] *= netout[..., 5:] > obj_thresh\n",
    "\n",
    "    for i in range(grid_h * grid_w):\n",
    "        row = i / grid_w\n",
    "        col = i % grid_w\n",
    "\n",
    "        for b in range(nb_box):\n",
    "            # 4th element is objectness score\n",
    "            objectness = netout[int(row)][int(col)][b][4]\n",
    "            # objectness = netout[..., :4]\n",
    "\n",
    "            if (objectness.all() <= obj_thresh): continue\n",
    "\n",
    "            # first 4 elements are x, y, w, and h\n",
    "            x, y, w, h = netout[int(row)][int(col)][b][:4]\n",
    "\n",
    "            x = (col + x) / grid_w  # center position, unit: image width\n",
    "            y = (row + y) / grid_h  # center position, unit: image height\n",
    "            w = anchors[2 * b + 0] * np.exp(w) / net_w  # unit: image width\n",
    "            h = anchors[2 * b + 1] * np.exp(h) / net_h  # unit: image height\n",
    "\n",
    "            # last elements are class probabilities\n",
    "            classes = netout[int(row)][col][b][5:]\n",
    "\n",
    "            box = BoundBox(x - w / 2, y - h / 2, x + w / 2, y + h / 2, objectness, classes)\n",
    "            # box = BoundBox(x-w/2, y-h/2, x+w/2, y+h/2, None, classes)\n",
    "\n",
    "            boxes.append(box)\n",
    "\n",
    "    return boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e3a6352e-a449-43f3-a402-4b6649e84d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_yolo_boxes(boxes, image_h, image_w, net_h, net_w):\n",
    "    if (float(net_w) / image_w) < (float(net_h) / image_h):\n",
    "        new_w = net_w\n",
    "        new_h = (image_h * net_w) / image_w\n",
    "    else:\n",
    "        new_h = net_w\n",
    "        new_w = (image_w * net_h) / image_h\n",
    "\n",
    "    for i in range(len(boxes)):\n",
    "        x_offset, x_scale = (net_w - new_w) / 2. / net_w, float(new_w) / net_w\n",
    "        y_offset, y_scale = (net_h - new_h) / 2. / net_h, float(new_h) / net_h\n",
    "\n",
    "        boxes[i].xmin = int((boxes[i].xmin - x_offset) / x_scale * image_w)\n",
    "        boxes[i].xmax = int((boxes[i].xmax - x_offset) / x_scale * image_w)\n",
    "        boxes[i].ymin = int((boxes[i].ymin - y_offset) / y_scale * image_h)\n",
    "        boxes[i].ymax = int((boxes[i].ymax - y_offset) / y_scale * image_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c0c025aa-a281-48d5-811a-cd30fc1eba6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_nms(boxes, nms_thresh):\n",
    "    if len(boxes) > 0:\n",
    "        nb_class = len(boxes[0].classes)\n",
    "    else:\n",
    "        return\n",
    "\n",
    "    for c in range(nb_class):\n",
    "        sorted_indices = np.argsort([-box.classes[c] for box in boxes])\n",
    "\n",
    "        for i in range(len(sorted_indices)):\n",
    "            index_i = sorted_indices[i]\n",
    "\n",
    "            if boxes[index_i].classes[c] == 0: continue\n",
    "\n",
    "            for j in range(i + 1, len(sorted_indices)):\n",
    "                index_j = sorted_indices[j]\n",
    "\n",
    "                if bbox_iou(boxes[index_i], boxes[index_j]) >= nms_thresh:\n",
    "                    boxes[index_j].classes[c] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "05e11207-c3d5-4c31-ac23-e8dff371e15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_boxes(image, boxes, line, labels, obj_thresh, dcnt):\n",
    "    print(line)\n",
    "\n",
    "    for box in boxes:\n",
    "        label_str = ''\n",
    "        label = -1\n",
    "\n",
    "        for i in range(len(labels)):\n",
    "            if box.classes[i] > obj_thresh:\n",
    "                label_str += labels[i]\n",
    "                label = i\n",
    "                print(labels[i] + ': ' + str(box.classes[i] * 100) + '%')\n",
    "                print('line: (' + str(line[0][0]) + ', ' + str(line[0][1]) + ') (' + str(line[1][0]) + ', ' + str(\n",
    "                    line[1][1]) + ')')\n",
    "                print('Box: (' + str(box.xmin) + ', ' + str(box.ymin) + ') (' + str(box.xmax) + ', ' + str(\n",
    "                    box.ymax) + ')')\n",
    "                print()\n",
    "\n",
    "        if label >= 0:\n",
    "            tf = False\n",
    "\n",
    "            (rxmin, rymin) = (box.xmin, box.ymin)\n",
    "            (rxmax, rymax) = (box.xmax, box.ymax)\n",
    "\n",
    "            tf = False\n",
    "            tf |= intersection(line[0], line[1], (rxmin, rymin), (rxmin, rymax))\n",
    "            tf |= intersection(line[0], line[1], (rxmax, rymin), (rxmax, rymax))\n",
    "            tf |= intersection(line[0], line[1], (rxmin, rymin), (rxmax, rymin))\n",
    "            tf |= intersection(line[0], line[1], (rxmin, rymax), (rxmax, rymax))\n",
    "\n",
    "            print(tf)\n",
    "\n",
    "            cv2.line(image, line[0], line[1], (255, 0, 0), 3)\n",
    "\n",
    "            if tf:\n",
    "                cv2.rectangle(image, (box.xmin, box.ymin), (box.xmax, box.ymax), (255, 0, 0), 3)\n",
    "                cimg = image[box.ymin:box.ymax, box.xmin:box.xmax]\n",
    "                cv2.imshow(\"violation\", cimg)\n",
    "                cv2.waitKey(5)\n",
    "                cv2.imwrite(\"Detected Images/violation_\" + str(dcnt) + \".jpg\", cimg)\n",
    "                dcnt = dcnt + 1\n",
    "            else:\n",
    "                cv2.rectangle(image, (box.xmin, box.ymin), (box.xmax, box.ymax), (0, 255, 0), 3)\n",
    "\n",
    "            cv2.putText(image,\n",
    "                        label_str + ' ' + str(round(box.get_score(), 2)),\n",
    "                        (box.xmin, box.ymin - 13),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                        1e-3 * image.shape[0],\n",
    "                        (0, 255, 0), 2)\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "400048ea-bb6d-4528-8437-d88cede65ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_path = \"yolov3.weights\"\n",
    "# set some parameters\n",
    "net_h, net_w = 416, 416\n",
    "obj_thresh, nms_thresh = 0.5, 0.45\n",
    "anchors = [[116, 90, 156, 198, 373, 326], [30, 61, 62, 45, 59, 119], [10, 13, 16, 30, 33, 23]]\n",
    "labels = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"aeroplane\", \"bus\", \"train\", \"truck\", \\\n",
    "          \"boat\", \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\", \\\n",
    "          \"bird\", \"cat\", \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\", \\\n",
    "          \"backpack\", \"umbrella\", \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\", \\\n",
    "          \"sports ball\", \"kite\", \"baseball bat\", \"baseball glove\", \"skateboard\", \"surfboard\", \\\n",
    "          \"tennis racket\", \"bottle\", \"wine glass\", \"cup\", \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \\\n",
    "          \"apple\", \"sandwich\", \"orange\", \"broccoli\", \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\", \\\n",
    "          \"chair\", \"sofa\", \"pottedplant\", \"bed\", \"diningtable\", \"toilet\", \"tvmonitor\", \"laptop\", \"mouse\", \\\n",
    "          \"remote\", \"keyboard\", \"cell phone\", \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\", \\\n",
    "          \"book\", \"clock\", \"vase\", \"scissors\", \"teddy bear\", \"hair drier\", \"toothbrush\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1d286684-2c95-4390-8884-2f95cb152326",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-18 07:27:21.104798: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/u187461/.local/lib/python3.9/site-packages/cv2/../../lib64:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/vpl/2023.0.0/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/tbb/2021.8.0/env/../lib/intel64/gcc4.8:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/rkcommon/1.10.0/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/ospray_studio/0.11.1/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/ospray/2.10.0/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/openvkl/1.3.1/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/oidn/1.4.3/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/mpi/2021.8.0//libfabric/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/mpi/2021.8.0//lib/release:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/mpi/2021.8.0//lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/mkl/2023.0.0/lib/intel64:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/itac/2021.8.0/slib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/ispc/1.18.1/lib/lib64:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/ipp/2021.7.0/lib/intel64:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/ippcp/2021.6.3/lib/intel64:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/ipp/2021.7.0/lib/intel64:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/embree/3.13.5/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/dnnl/2023.0.0/cpu_dpcpp_gpu_dpcpp/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/debugger/2023.0.0/gdb/intel64/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/debugger/2023.0.0/libipt/intel64/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/debugger/2023.0.0/dep/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/dal/2023.0.0/lib/intel64:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/compiler/2023.0.0/linux/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/compiler/2023.0.0/linux/lib/x64:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/compiler/2023.0.0/linux/lib/oclfpga/host/linux64/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/compiler/2023.0.0/linux/compiler/lib/intel64_lin:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/ccl/2021.8.0/lib/cpu_gpu_dpcpp\n",
      "2023-03-18 07:27:21.104859: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-03-18 07:27:21.104902: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (s001-n066): /proc/driver/nvidia/version does not exist\n",
      "2023-03-18 07:27:21.121365: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# make the yolov3 model to predict 80 classes on COCO\n",
    "yolov3 = make_yolov3_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4759836b-1773-42e2-b195-6c7fc97b9d87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading weights of convolution #0\n",
      "loading weights of convolution #1\n",
      "loading weights of convolution #2\n",
      "loading weights of convolution #3\n",
      "no convolution #4\n",
      "loading weights of convolution #5\n",
      "loading weights of convolution #6\n",
      "loading weights of convolution #7\n",
      "no convolution #8\n",
      "loading weights of convolution #9\n",
      "loading weights of convolution #10\n",
      "no convolution #11\n",
      "loading weights of convolution #12\n",
      "loading weights of convolution #13\n",
      "loading weights of convolution #14\n",
      "no convolution #15\n",
      "loading weights of convolution #16\n",
      "loading weights of convolution #17\n",
      "no convolution #18\n",
      "loading weights of convolution #19\n",
      "loading weights of convolution #20\n",
      "no convolution #21\n",
      "loading weights of convolution #22\n",
      "loading weights of convolution #23\n",
      "no convolution #24\n",
      "loading weights of convolution #25\n",
      "loading weights of convolution #26\n",
      "no convolution #27\n",
      "loading weights of convolution #28\n",
      "loading weights of convolution #29\n",
      "no convolution #30\n",
      "loading weights of convolution #31\n",
      "loading weights of convolution #32\n",
      "no convolution #33\n",
      "loading weights of convolution #34\n",
      "loading weights of convolution #35\n",
      "no convolution #36\n",
      "loading weights of convolution #37\n",
      "loading weights of convolution #38\n",
      "loading weights of convolution #39\n",
      "no convolution #40\n",
      "loading weights of convolution #41\n",
      "loading weights of convolution #42\n",
      "no convolution #43\n",
      "loading weights of convolution #44\n",
      "loading weights of convolution #45\n",
      "no convolution #46\n",
      "loading weights of convolution #47\n",
      "loading weights of convolution #48\n",
      "no convolution #49\n",
      "loading weights of convolution #50\n",
      "loading weights of convolution #51\n",
      "no convolution #52\n",
      "loading weights of convolution #53\n",
      "loading weights of convolution #54\n",
      "no convolution #55\n",
      "loading weights of convolution #56\n",
      "loading weights of convolution #57\n",
      "no convolution #58\n",
      "loading weights of convolution #59\n",
      "loading weights of convolution #60\n",
      "no convolution #61\n",
      "loading weights of convolution #62\n",
      "loading weights of convolution #63\n",
      "loading weights of convolution #64\n",
      "no convolution #65\n",
      "loading weights of convolution #66\n",
      "loading weights of convolution #67\n",
      "no convolution #68\n",
      "loading weights of convolution #69\n",
      "loading weights of convolution #70\n",
      "no convolution #71\n",
      "loading weights of convolution #72\n",
      "loading weights of convolution #73\n",
      "no convolution #74\n",
      "loading weights of convolution #75\n",
      "loading weights of convolution #76\n",
      "loading weights of convolution #77\n",
      "loading weights of convolution #78\n",
      "loading weights of convolution #79\n",
      "loading weights of convolution #80\n",
      "loading weights of convolution #81\n",
      "no convolution #82\n",
      "no convolution #83\n",
      "loading weights of convolution #84\n",
      "no convolution #85\n",
      "no convolution #86\n",
      "loading weights of convolution #87\n",
      "loading weights of convolution #88\n",
      "loading weights of convolution #89\n",
      "loading weights of convolution #90\n",
      "loading weights of convolution #91\n",
      "loading weights of convolution #92\n",
      "loading weights of convolution #93\n",
      "no convolution #94\n",
      "no convolution #95\n",
      "loading weights of convolution #96\n",
      "no convolution #97\n",
      "no convolution #98\n",
      "loading weights of convolution #99\n",
      "loading weights of convolution #100\n",
      "loading weights of convolution #101\n",
      "loading weights of convolution #102\n",
      "loading weights of convolution #103\n",
      "loading weights of convolution #104\n",
      "loading weights of convolution #105\n"
     ]
    }
   ],
   "source": [
    "# load the weights trained on COCO into the model\n",
    "weight_reader = WeightReader(weights_path)\n",
    "weight_reader.load_weights(yolov3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "788801cf-a0c8-463a-badb-eb031ca0f58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# my defined functions\n",
    "def intersection(p, q, r, t):\n",
    "    print(p, q, r, t)\n",
    "    (x1, y1) = p\n",
    "    (x2, y2) = q\n",
    "\n",
    "    (x3, y3) = r\n",
    "    (x4, y4) = t\n",
    "\n",
    "    a1 = y1 - y2\n",
    "    b1 = x2 - x1\n",
    "    c1 = x1 * y2 - x2 * y1\n",
    "\n",
    "    a2 = y3 - y4\n",
    "    b2 = x4 - x3\n",
    "    c2 = x3 * y4 - x4 * y3\n",
    "\n",
    "    if (a1 * b2 - a2 * b1 == 0):\n",
    "        return False\n",
    "    print((a1, b1, c1), (a2, b2, c2))\n",
    "    x = (b1 * c2 - b2 * c1) / (a1 * b2 - a2 * b1)\n",
    "    y = (a2 * c1 - a1 * c2) / (a1 * b2 - a2 * b1)\n",
    "    print((x, y))\n",
    "\n",
    "    if x1 > x2:\n",
    "        tmp = x1\n",
    "        x1 = x2\n",
    "        x2 = tmp\n",
    "    if y1 > y2:\n",
    "        tmp = y1\n",
    "        y1 = y2\n",
    "        y2 = tmp\n",
    "    if x3 > x4:\n",
    "        tmp = x3\n",
    "        x3 = x4\n",
    "        x4 = tmp\n",
    "    if y3 > y4:\n",
    "        tmp = y3\n",
    "        y3 = y4\n",
    "        y4 = tmp\n",
    "\n",
    "    if x >= x1 and x <= x2 and y >= y1 and y <= y2 and x >= x3 and x <= x4 and y >= y3 and y <= y4:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118d1b30-2f89-4656-a396-608b34ace709",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oneAPI 2022.3.1",
   "language": "python",
   "name": "2022.3.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
